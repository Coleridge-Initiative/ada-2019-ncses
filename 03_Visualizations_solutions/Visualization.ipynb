{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: center;\" src=\"images/CI_horizontal.png\" width=\"600\">\n",
    "<center>\n",
    "    <span style=\"font-size: 1.5em;\">\n",
    "        <a href='https://www.coleridgeinitiative.org'>Website</a>\n",
    "    </span>\n",
    "</center>\n",
    "\n",
    "# Data Visualization in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module, you will learn to quickly and flexibly generate a range of visualizations to explore data and communicate with your audience. This module contains a practical introduction to data visualization in Python and covers important rules to follow when creating visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Learn critical rules about data visualization (selecting graph types; labeling visual encodings; referencing data sources).\n",
    "\n",
    "* Become familiar with two core Python data visualization tools, Matplotlib and seaborn.\n",
    "\n",
    "* Start to develop the ability to conceptualize which visualizations can best reveal various types of patterns in your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a Data Visualization Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- \n",
    "Matplotlib is always capitalized, like a typical proper noun.\n",
    "Seaborn is capitalized like an ordinary word, so it's lowercase if \"seaborn\" appears in the middle of a sentence.\n",
    "-->\n",
    "\n",
    "There are many excellent data visualization modules available in Python. You can read more about different options for data visualization in Python in the [More Resources](#More-Resources:) section at the bottom of this notebook. For this the tutorial we will stick to a tried and true combination of 2-D plotting libraries: Matplotlib and seaborn.\n",
    "\n",
    "Matplotlib is very expressive, meaning that it has functionality to allow extensive and fine-tuned creation of figures. It makes no assumptions about data, so it can be used to make historical timelines and fractals as well as bar charts and scatter plots. Matplotlib's flexibility comes at the cost of additional complexity in its use. \n",
    "\n",
    "Seaborn is a higher-level module, trading some of the expressiveness and flexibility of matplotlib for more concise and easier syntax. For our purposes, Seaborn improves on Matplotlib in several ways, making it easier to create small multiples, improving the color and aesthetics, and including direct support for some visualizations such as regression model results. Seaborn's creator, Michael Waskom, has compared the two:\n",
    "\n",
    "> If Matplotlib \"tries to make easy things easy and hard things possible\", seaborn tries to make a well-defined set of hard things easy too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn and Matplotlib together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may seem like we need to choose between these two approaches, but happily this is not the case. Seaborn is itself written in Matplotlib (and you will sometimes see seaborn called a \"wrapper\" around Matplotlib). We can use seaborn to make graphs quickly,  then Matplotlib for specific adjustments. Whenever you see `plt` referenced in the code below, we are using a submodule of `matplotlib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages and Set Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These abbreviations (pandas -> pd; seaborn -> sns) may seem arbitrary,\n",
    "# but they are community conventions that will help keep your work easy\n",
    "# to read and compare with that of other Python users.\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Jupyter-specific \"magic command\" to plot images directly in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# Engine to connect to SQL database\n",
    "# We'll create this once and provide to pandas whenever we use read_sql()\n",
    "engine = create_engine(\"postgresql://stuffed.adrf.info/appliedda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "In this notebook, we are going to tackle a series of questions. To answer them, we will introduce you to various visualizations which will provide a clearer view of the data than just using summary statistics, and help you create powerful graphics that better convey the point you want to make.\n",
    "\n",
    "The questions we will focus on this notebook are:\n",
    "- About how old are graduate students when they finish their dissertations? That is, what is the distribution of age at dissertation? How does this differ by field of study?\n",
    "- What are the differences in starting salary by field of PhD? How has starting salary changed over the years, both overall and by field?\n",
    "- What are primary sources of funding for students in various fields of study?\n",
    "- What are the funding histories of graduate students in the three years leading up to their dissertation? How do the funding histories differ, and what are the most frequent funding sequences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DataFrames\n",
    "\n",
    "We've separated out the SQL queries constructing the Data Frames that we will use for this notebook, and read them in from `.sql` files. Since they are not the focus of this notebook, we won't go into detail on how we've built up the queries, but we suggest you take a look at the `joined_person.sql` and `joined_semester.sql` files to make sure you understand how they're created.\n",
    "\n",
    "`person_df` is at the individual level across the entire range and has individual level statistics on characteristics such as their demographics, academic achievements and debt levels.\n",
    "\n",
    "`semester_df` is at the person-semester level and has information about their funders, team size, and semester.\n",
    "\n",
    "In both of these Data Frames, we've done some cleaning in SQL (which you can see in the `.sql` files) to help facilitate our visualization creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "person_level_query = Path('./joined_person.sql').read_text()\n",
    "person_df = pd.read_sql(person_level_query, engine)\n",
    "person_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "semester_level_query = Path('./joined_semester.sql').read_text()\n",
    "\n",
    "semester_df = pd.read_sql(semester_level_query, engine)\n",
    "semester_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin with some straightforward Matplotlib functions. We'll start with some motivation questions, then use the appropriate Matplotlib commands to create a visualization that helps answer that question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When designing visualizations, it can help to just draw a sketch on paper first. Once you have an idea of what type of graph is best suited to illustrate the fact that you want to show, consider how to prepare the data you need for the graph. \n",
    "\n",
    "We can provide Matplotlib a `pd.DataFrame` or `pd.Series` that we've created using Pandas. We'll want to ensure that the DataFrame includes exactly the information we want to plot, because Matplotlib won't be doing much more than simple aggregation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Histogram\n",
    "\n",
    "**Motivating Question: About how old are graduate students when they finish their dissertations? That is, what is the distribution of age at dissertation? How does this differ by field of study?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since age is a numerical variable, we'll want to use a visualization such as a histogram. We'll start by plotting a histogram of a single variable, then customizing the figure. For a histogram, we'll want to consider the scale -- whether we should plot everything or a subset of values. Plotting our data as a histogram makes it easier to quickly observe some features, such as the overall shape of the distribution and its skewness and kurtosis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, we'll just take a single series: age at dissertation\n",
    "ages = person_df.age_at_diss.dropna()\n",
    "ages.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "An easy way to get started with Matplotlib is to use its state-based interface, `matplotlib.pyplot`, which we have already imported above as `plt`. We can create a graph, then adjust its current state a bit at a time using `plt` functions.\n",
    "\n",
    "To create a new histogram, we'll simply pass our team size series into `plt.hist()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ages)\n",
    "\n",
    "# The show() function outputs the current state of `pyplot`: our current fig.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.describe()` above already suggested a strong right skew, but this visualization shows us the distribution in much greater detail.\n",
    "\n",
    "But this is bare: let's at least add some labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ages)\n",
    "\n",
    "plt.ylabel('Dissertators', fontsize='medium', labelpad=10)\n",
    "plt.xlabel('Age', fontsize='medium', labelpad=10)\n",
    "\n",
    "# In the notebook environment, the figure will automatically be\n",
    "# displayed if the Python code cell ends with an update to the plot,\n",
    "# so we can skip plt.show() in many cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Built-in styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "Now let's see how we can improve the style of this visualization. Every part of this figure can be customized in several ways, and Matplotlib includes several popular styles built-in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Built-in style names:', ', '.join(sorted(plt.style.available)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the default style (affects font, color, positioning, and more)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.xlabel('Age', fontsize='medium', labelpad=10)\n",
    "plt.ylabel('Dissertators', fontsize='medium', labelpad=10)\n",
    "\n",
    "# We need to replot the data in each newnotebook cell.\n",
    "plt.hist(ages, bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Style customization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "That's a bit better, but Matplotlib allows us to customize every individual component on the fly.\n",
    "\n",
    "> *How can we reset customizations?* In a notebook with multiple figures, we may want to reset everything before our next visualization. Or, having explored several options, we might want to undo all the stylistic tweaks without having to rerun the entire notebook. `matplotlib.rc_file_defaults()` will return just about everything to default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rc_file_defaults()\n",
    "\n",
    "# Change the figure size -- let's make it big.\n",
    "plt.rc('figure', figsize=(8, 5))\n",
    "\n",
    "# Because `pyplot` works by incrementally updating the state of `plt`,\n",
    "# some changes must be made prior to creating those elements in the figure.\n",
    "# We'll make the axes spines (the box around the plot) invisible\n",
    "mpl.rc('axes', edgecolor='white', titlepad=20)\n",
    "\n",
    "# These will remove the axes ticks\n",
    "mpl.rc('xtick', bottom=False)\n",
    "mpl.rc('ytick', left=False)\n",
    "\n",
    "# Now we'll replot the data. With such a large sample, let's make a bin for each year.\n",
    "n_bins = int(ages.max() - ages.min())\n",
    "plt.hist(\n",
    "    ages, \n",
    "    bins=n_bins, \n",
    "    align='left',\n",
    "    color='xkcd:sage'\n",
    ")\n",
    "\n",
    "# Just after adding the data is a good time to remember to source it.\n",
    "plt.annotate(\n",
    "    'Sources: NCSES SED', \n",
    "    fontsize='x-small',\n",
    "    xycoords=\"figure fraction\", # specify x and y positions as % of the overall figure\n",
    "    xy=(1, 0.01), # 100% to the right (x) and 1% to the top (y) means bottom right\n",
    "    horizontalalignment='right', # the text will align appropriately for bottom right\n",
    ")\n",
    "\n",
    "# Add a title to the top of the figure\n",
    "plt.title(\"Dissertations Typically Completed Near Age Thirty\", fontsize='large')\n",
    "\n",
    "# Add axis labels, with a bit more padding than default between the label and the axes\n",
    "plt.xlabel('Age of Dissertator', fontsize='medium', labelpad=10)\n",
    "plt.ylabel('Number of Dissertations', fontsize='medium', labelpad=10)\n",
    "\n",
    "# Reduce the size of the axis labels\n",
    "plt.xticks(fontsize=9)\n",
    "plt.yticks(fontsize=9)\n",
    "\n",
    "# Add horizontal gridlines using negative space across the bars\n",
    "plt.grid(\n",
    "    color='white', \n",
    "    linewidth=1,\n",
    "    axis='y'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Data sourcing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "A critical aspect of any data visualization intended for release is a reference to the source of the data being used. In these examples, we simply reference the agencies and names of the datasets. Whenever possible, we would provide a direct path so that our audience can find the data we used to build the figure. When this is feasible  -- as with these restricted-access data -- be sure to direct the reader to documentation describing the data.\n",
    "\n",
    "Either way, providing clear sourcing for the underlying data is an absolute requirement of responsible dissemination. Transparent communication of sources and references builds trust between analyst and audience and helps enable the reproducibility of analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "toc-hr-collapsed": true
   },
   "outputs": [],
   "source": [
    "# If we're repeatedly doing the same kind of annotation, \n",
    "# it helps a lot to turn that into a function.\n",
    "def add_sourcing(plt, source_string, fontsize='x-small'):\n",
    "    \"\"\"Add small sourcing note to lower-right of current plot\n",
    "    \n",
    "    We would be using the same arguments over and over to do this.\n",
    "    So a quick function will make it simpler. Now we can simply:\n",
    "    \n",
    "    add_sourcing(plt, 'Sources: IRIS UMETRICS, NCSES SED')\n",
    "    \"\"\"\n",
    "    return plt.annotate(\n",
    "        source_string,\n",
    "        fontsize=fontsize,\n",
    "        xycoords=\"figure fraction\", # specify x and y positions as % of the overall figure\n",
    "        xy=(1, 0.01), # 100% to the right (x) and 1% to the top (y) means bottom right\n",
    "        horizontalalignment='right', # the text will align appropriately for bottom right    \n",
    "    )\n",
    "print(\"Now we can simply run:\\n   add_sourcing(plt, 'Text goes here')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple plots in one figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib is allowing us to make consecutive changes to the same plot, then display it whenever we're ready. The same process allows us to layer on multiple plots. By default, the first graph you create will be at the lowest layer, with each successive graph layered on top.\n",
    "\n",
    "Below, we observe a difference in mean age of dissertation by field. Let's overlay one of the higher and one of the lower, to visualize the difference in their distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df.groupby('phd_major_field')['age_at_diss'].agg(['mean', 'count']).sort_values('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = ['Physical Sciences', 'Education']\n",
    "\n",
    "# Create a subset of person_df, plottinga histogram of age for each\n",
    "for major_field in fields_of_interest:\n",
    "    field_ages = person_df[person_df.phd_major_field == major_field].age_at_diss.dropna()\n",
    "    plt.hist(field_ages, bins='doane', alpha=0.5)\n",
    "    \n",
    "# We'll definitely need a label to keep these apart...\n",
    "plt.legend(\n",
    "    labels=fields_of_interest, #ensure that labels are in the same order as above\n",
    "    loc='center right', # the default is upper right, so move a little closer\n",
    "    frameon=False, # remove the box around the legend\n",
    ")\n",
    "\n",
    "add_sourcing(plt, 'Sources: NCSES SED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "<font color = red> <h2>Checkpoint #1: Histogram</h2></font>\n",
    "\n",
    "Try customizing your own histogram. If you want to try something other than age, another continuous variable in `person_df` is `salary_k`, the PhD graduate's anticipated salary (in thousands). Or `semester_df` includes the `team_size` variable, measuring the size of the federally-funded teams that a student is working with in each semester.\n",
    "\n",
    "You'll definitely want to include:\n",
    "- A title (`plt.title`)\n",
    "- Axis labels (`plt.xlabel` and `plt.ylabel`)\n",
    "- Data sourcing (`plt.annotate` or the `add_sourcing` function defined above)\n",
    "\n",
    "If you use multiple colors, you'll want to add a legend as well (`plt.legend`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will change the variable from `age_at_diss` to `salary_k`. We add `plt.title`, `plt.xlabel`, `plt.ylabel`, `add_sourcing` function. If you want to change the range of the bins on x-axis, you can use `plt.xlim` and define the needed range (e.g. from 0 to 200K). To change the range on the y-axis, you can use `plt.ylim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_of_interest = ['Physical Sciences', 'Education']\n",
    "\n",
    "# Create a subset of person_df, plottinga histogram of age for each\n",
    "for major_field in fields_of_interest:\n",
    "    field_salary = person_df[person_df.phd_major_field == major_field].salary_k.dropna()\n",
    "    plt.hist(field_salary, bins='doane', alpha=0.5)\n",
    "    plt.title('Most students expect salary to be between $35-75K')\n",
    "    plt.xlabel('Anticipated salary')\n",
    "    plt.ylabel('Number of students')\n",
    "    plt.xlim(0,200)  # specify the bin range\n",
    "    \n",
    "# We'll definitely need a label to keep these apart...\n",
    "plt.legend(\n",
    "    labels=fields_of_interest, #ensure that labels are in the same order as above\n",
    "    loc='center right', # the default is upper right, so move a little closer\n",
    "    frameon=False, # remove the box around the legend\n",
    ")\n",
    "\n",
    "add_sourcing(plt, 'Sources: NCSES SED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn provides a high-level interface to Matplotlib, which is powerful but sometimes unwieldy. Seaborn provides many useful defaults, so that we can quickly have:\n",
    "- More aesthetically pleasing defaults\n",
    "- A better range of color palettes\n",
    "- More complex graphs with less code\n",
    "- Small multiples (a sequence of small graphs in one figure)\n",
    "\n",
    "As you'll see, these libraries are complementary. Some tweaks will still require reaching back into Matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar chart\n",
    "\n",
    "For this section, consider the following question:\n",
    "\n",
    "**What are the differences in starting salary by field of PhD? How has starting salary changed over the years, both overall and by field?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bar plot presents categorical data with rectangular bars proportional to the values that they represent. In this case, we plot a horizontal bar plot. A bar plot represent an estimate of central tendency for a numeric variable with the length of each rectangle, and the seaborn `barplot()` function also includes an indication of the uncertainty around the estimate using error bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rc_file_defaults() # reset most Matplotlib features to defaults\n",
    "\n",
    "# By convention, a returned Axes object is often called `ax`\n",
    "ax = sns.barplot(\n",
    "    y=\"phd_major_field\", # seaborn is clever enough to create a horizontal chart\n",
    "    x=\"salary_k\", \n",
    "    data=person_df.sort_values('phd_major_field'), # order in data to order in figure\n",
    ")\n",
    "\n",
    "# We can use either `ax` or `plt` here; either will work\n",
    "add_sourcing(ax, 'Sources: NCSES SED')\n",
    "\n",
    "ax.set_title('Anticipated Salary Varies Considerably Across Fields of PhD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a line plot (seaborn `lineplot()` function) for tracking change in a value over time (a time series graph). Here we look at trend in salary expectations over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: The title of a visualization occupies the most valuable real estate on the page. If nothing else, you can be reasonably sure a viewer will at least read the title and glance at your visualization. This is why you want to put thought into making a clear and effective title that acts as a **narrative** for your chart. It is best to avoid _explanatory_ titles, such as: \"Average Expected Salary over Time (2008-2017)\". This title is correct, yes -- but it isn't very useful. It is likely to be redundant, since \"salary\" and \"year\" are probably labels on the axes already. Instead, use the title to reinforce and explain the core point of the visualization. It should answer the question **\"Why is this graph important?\"** and focus the viewer onto the most critical take-away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rc_file_defaults() # reset most settings to defaults\n",
    "\n",
    "# A `with` statement (context manager) can be used to temporarily set figure styles\n",
    "with sns.axes_style('darkgrid'):\n",
    "    axes = sns.lineplot(data=person_df, x='phd_year', y='salary_k', color=\"#229900\")\n",
    "    axes.set_title('Anticipated Salary Has Been Increasing')\n",
    "\n",
    "add_sourcing(plt, 'Sources: IRIS UMETRICS, NCSES SED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small multiples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small multiples can be a great way to compare across categories, so that we can see several similarly plotted versions in the same overall figure. Seaborn offers an  easy interface for combining multiple plots into a single figure using the `FacetGrid` class. Because `FacetGrid` was designed for exactly this use, seaborn has helpful defaults such as automatically synchronized axes.\n",
    "\n",
    "We've looked at salary expectations over time and across field; here we consider all three variables at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare our grid, which will share axes across multiple plots (wrapping after 5 columns)\n",
    "g = sns.FacetGrid(person_df, col='phd_major_field', ylim=(0, 140), col_wrap=5)\n",
    "\n",
    "# Create a lineplot for each cell of the grid\n",
    "g = g.map(sns.lineplot, \"phd_year\", \"salary_k\")\n",
    "\n",
    "add_sourcing(plt, 'Source: NCSES SED', fontsize='medium')\n",
    "\n",
    "# Simplify the titles inside each cell\n",
    "g.set_titles(\"{col_name}\")\n",
    "\n",
    "# Remove the spine (vertical line) along the y axis\n",
    "sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The colors used in figures in both Matplotlib and seaborn can be represented in code in many ways, but here are two that Matplotlib, seaborn, and many other modern visualization packages handle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hex triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hex triplet is a specification for the RGB color model commonly used for website and browser-rendered colors. These are formatted as a string with a pound sign `#` followed by a series of six numbers. Each pair of hexadecimal digits (i.e., two of 0-9 and A-F) represents two bytes of color information for red, green, and blue, in that order: `\"#RRGGBB\"`. A low value (minimum 00) contributes less of that primary color, a high value (maximum FF) a larger amount. Together, these can specify over 16 million colors. An additional two hex digits can be added to indicate alpha (transparency) where 00 is completely transparent and FF is completely opaque. Hex triplets are very common across many platforms and packages well beyond data and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XKCD names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A relatively new standard, XKCD names were the result of an online study created by Randall Monroe where volunteers entered free-form names of colors displayed on screen. Following the input of tens of thousands of participants, 954 common and distinguishing names were codified. Behind the scenes, these are still equivalent to specific hex triplets, but they can be more convenient. The result is a list of color names that many English speakers will find intuitive, from basics such as \"gold,\" \"green,\" and \"light grey\" to rarely used terms. In Matplotlib and seaborn these are written as a string prefixed by `xkcd:`, for example: `\"xkcd:cement\"` (#a5a391), `\"xkcd:pale magenta\"` (#d767ad), `\"xkcd:sage\"` (#87ae73), and `\"xkcd:green/blue\"` (#01c08d)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "<font color = red><h2> Checkpoint #2: Small Multiples </h2></font>\n",
    "\n",
    "Trying using `sns.FacetGrid` in combination with a histogram, bar, or line chart of your choice. Separating simple charts into several categories with small multiples can be a big improvement over trying to graph several things on the same chart.\n",
    "\n",
    "Try experimenting with color choices. Remember to add source and use a title that highlights the main take-away."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to include another variable in a line plot, for example, to look at differences by gender, you can use the `hue = 'sex'` variable in the `FacetGrid` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "toc-hr-collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare our grid, which will share axes across multiple plots (wrapping after 5 columns)\n",
    "g = sns.FacetGrid(person_df, col='phd_major_field', hue='sex', ylim=(0, 140), col_wrap=5)\n",
    "\n",
    "# Create a lineplot for each cell of the grid\n",
    "g = g.map(sns.lineplot, \"phd_year\", \"salary_k\")\n",
    "\n",
    "add_sourcing(plt, 'Source: NCSES SED', fontsize='medium')\n",
    "\n",
    "# Simplify the titles inside each cell\n",
    "g.set_titles(\"{col_name}\")\n",
    "\n",
    "# Remove the spine (vertical line) along the y axis\n",
    "sns.despine(left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More visualization methods and motivating examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent a relationship between the age of doctorate recipients and their expected salaries using a scatter plot and seaborn `scatterplot()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_df = person_df[person_df.salary_k < 300]\n",
    "ax = sns.scatterplot(\n",
    "    x='age_at_diss', \n",
    "    y='salary_k', \n",
    "    color=\"xkcd:sea blue\",\n",
    "    data=scatter_df,\n",
    "    alpha=.1, # we have a LOT of points, so make each nearly transparent\n",
    "    linewidth=0, # and remove the default (white) circle around each\n",
    ")\n",
    "add_sourcing(plt, 'Sources: IRIS UMETRICS, NCSES SED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "### Heat map\n",
    "\n",
    "Consider the following question:\n",
    "\n",
    "**What are primary sources of funding for students in various fields of study?**\n",
    "\n",
    "For something like this, we might want to use a heatmap. This can give a sort of visual summary similar to a crosstab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "toc-hr-collapsed": true
   },
   "outputs": [],
   "source": [
    "MAJOR_FUNDERS = 'NIH NSF DOD DOE USDA NASA ED'.split()\n",
    "\n",
    "pre_heatmap_df = pd.merge(semester_df, person_df, how='left', on='drf_id')[['modal_funder', 'phd_major_field']]\n",
    "\n",
    "heatmap_df = pd.crosstab(pre_heatmap_df.phd_major_field, pre_heatmap_df.modal_funder)[MAJOR_FUNDERS]\n",
    "\n",
    "ax = sns.heatmap(heatmap_df, cmap=sns.cubehelix_palette(light=1, as_cmap=True))\n",
    "add_sourcing(ax, 'Sources: IRIS UMETRICS, NCSES SED')\n",
    "\n",
    "# This heatmap fix is only necessary for 3.1.0 < Matplotlib <= 3.1.1; see https://stackoverflow.com/questions/56948670\n",
    "ax.set_ylim(len(heatmap_df), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Funding sequence chart\n",
    "\n",
    "Consider the following question:\n",
    "\n",
    "**What are the funding histories of graduate students in the three years leading up to their dissertation? How do the funding histories differ, and what are the most frequent funding sequences?**\n",
    "\n",
    "To create a graphic that lets us answer this question, we need both semester level funding information and time of dissertation. In other words, we need to use a linked dataset with UMETRICS and SED. The UMETRICS data allows us to get the funding history of students, which we can use in conjunction with SED data to see what the funding histories look like leading up to the dissertation.\n",
    "\n",
    "In the following, we use the flexibility of pandas and these visualization libraries to create an unusual kind of chart. We will display the top ten most common patterns of federal funding in the time before and during the year that a student receives the PhD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Conceptual design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "We have the idea, so we'll first want to think about what it will look like in the end, then work backwards to determine how we need to handle the data to create the table we'll need.\n",
    "\n",
    "It really helps to get concrete, particularly if you aren't doing a standard kind of figure. The final visualization we're aiming for will be organized something like this:\n",
    "\n",
    "```\n",
    "funding pattern \n",
    "\n",
    "- - - X X X X X X | 11%\n",
    "X X X X X X X X X | 10%\n",
    "- - - X X - X X - | 9%\n",
    "- - - X X X X X - | 8%\n",
    "- - - X X X X - - | 7%    percent\n",
    "- - X X X X - - - | 6%    of sample\n",
    "X X - - - - - - - | 5%\n",
    "- - - X X - - - - | 4%\n",
    "X X X - - - - - - | 4%\n",
    "- - - - X X X - - | 4%\n",
    "__________________|\n",
    " -2    -1     0\n",
    "      year\n",
    "\n",
    "```\n",
    "We'll put the percentages on the right, to help reinforce that we are looking back in time from the PhD award. Each row is a pattern where an `X` indicates federal funding and a `-` is no funded. If these were the real data, the first row would tell us that 11% of the PhD awardees had federal funding only during the last two years before their degree was awarded. The second row shows 10% with federal funding every single semester, nine in a row. The numbers here are arbitrary -- the point is to get a sense of what we're aiming for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "Before we get there, though, we'll have a fair amount of data preparation. We'll plan to use a heatmap to present the pattern of yes/no funding, which means an aggregated and simplified dataset to pass into seaborn.\n",
    "\n",
    "From end to beginning:\n",
    "  - Top ten rows by % of total, nine columns of yes/no semester funding\n",
    "  - ...will need to be counted from a unique student-level dataset that has nine columns of yes/no funding\n",
    "  - ...pivoted from the full student X semester-level dataset we have as `semester_df`\n",
    "  - ...created from those students we have covered in UMETRICS for the entire time period (we'll cut by institution)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DATA CLEANING\n",
    "\n",
    "# Sixteen schools have UMETRICS coverage 2012-2015, and we only want them for this chart\n",
    "sequence_sample = semester_df[semester_df['sequence_data_coverage'] == 1]\n",
    "\n",
    "\n",
    "# 2. PIVOT FROM STUDENTxSEMESTER TO STUDENT\n",
    "\n",
    "# W pivot to unique rows by person (drf_id) and a column for each semester\n",
    "pivoted = sequence_sample.pivot(index='drf_id', columns='semester', values='any_federal')\n",
    "\n",
    "# convert team_size to 1 if federal funding (True); 0 if not (NaN)\n",
    "pivoted = pivoted.applymap(lambda x: int(x == 1)) \n",
    "\n",
    "# We have two different phd_year so we'll need to adjust which semesters are relative to which\n",
    "pivoted = pivoted.merge(right=person_df[['drf_id', 'phd_year']], how='inner', on='drf_id')\n",
    "\n",
    "\n",
    "# 3. A WRINKLE IN THE DATA\n",
    "\n",
    "# Oops -- our data are recorded by calendar semester, but not everyone graduated in the same year: \n",
    "# some 2014, some 2015. We want relative semesters, so we need to account for that.\n",
    "\n",
    "# If we were doing to do this more than once, we'd probably want to create a function to do it automatically...\n",
    "phd2014 = pivoted[pivoted.phd_year == 2014][['12spr', '12sum', '12fal', '13spr', '13sum', '13fal', '14spr', '14sum', '14fal']]\n",
    "phd2015 = pivoted[pivoted.phd_year == 2015][['13spr', '13sum', '13fal', '14spr', '14sum', '14fal', '15spr', '15sum', '15fal']]\n",
    "\n",
    "RELATIVE_COLUMNS = ['-2 Spr', '-2 Sum', '-2 Fal', '-1 Spr', '-1 Sum', '-1 Fal', 'Spr', 'Sum', 'Fal']\n",
    "phd2015.columns = phd2014.columns = RELATIVE_COLUMNS\n",
    "\n",
    "# pd.concat() stacks them back together, now that we have re-synchronized their rows\n",
    "funding_df = pd.concat((phd2014, phd2015))\n",
    "\n",
    "# To clarify our sample, because our data are not independent of having received federal funding,\n",
    "# we'll just keep those that show any federal funding during these nine semesters.\n",
    "funding_df = funding_df[funding_df.sum(axis=1) > 0]\n",
    "\n",
    "\n",
    "# 4. AGGREGATING TOGETHER BY PATTERNS\n",
    "\n",
    "# We cluster the data by these semesters (equivalent to the list of columns)\n",
    "# using size() to count the number of dissertators with each pattern\n",
    "aggregated = funding_df.groupby(list(funding_df.columns)).size().reset_index()\n",
    "\n",
    "# Rename the not-so-helpful 0 column from groupby().size() into 'size'\n",
    "aggregated = aggregated.rename(columns={0: 'size'})\n",
    "# Keep only the most common ten patterns (10 rows with the highest value in the size column)\n",
    "aggregated = aggregated.nlargest(10, 'size')\n",
    "\n",
    "\n",
    "# 5. MINOR BITS OF FORMATTING\n",
    "\n",
    "# Convert the count size into percentage of the total students\n",
    "aggregated['size'] = aggregated['size'] / len(pivoted)\n",
    "# And format the new field so that it will be a nice percentage in our chart\n",
    "aggregated['size'] = aggregated['size'].apply(lambda x: '{:,.1%}'.format(float(x)))\n",
    "\n",
    "# Conveniently, seaborn will automatically use the index as the y-axis\n",
    "aggregated = aggregated.set_index('size')\n",
    "aggregated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's exactly the table we want. In reality, putting this together took several iterations to understand exactly how the data should be combined and to minimize errors in sample construction and aggregation.\n",
    "\n",
    "The `aggregated` df is now ready to pass into seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rc_file_defaults() # reset to defaults\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    aggregated, \n",
    "    cbar=False, # We don't need the heatmap's color bar \n",
    "    cmap='Greens', \n",
    "    linewidth=.5,  \n",
    ")\n",
    "add_sourcing(plt, 'Sources: IRIS UMETRICS, NCSES SED')\n",
    "\n",
    "# Move the y axis labels over to the right side to help guide the chronology\n",
    "ax.tick_params(left=False, bottom=False, labelleft=False, labelright=True, labelrotation=1)\n",
    "\n",
    "ax.set_title('Most Common Funding Patterns of Federally Funded PhD Recipients')\n",
    "ax.set_xlabel('Semesters of funding, relative to year of PhD')\n",
    "ax.set_ylabel('')\n",
    "\n",
    "# This heatmap fix is only necessary for 3.1.0 < Matplotlib <= 3.1.1; see https://stackoverflow.com/questions/56948670\n",
    "ax.set_ylim(len(aggregated), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Saving visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "When you are satisfied with your visualization, you will likely want a copy outside of your notebook. This can be done directly from the code using the `savefig` function of Matplotlib. When using `savefig`, the extension of the filename you choose is important. Image formats such as like PNG and JPEG are **not ideal**. Instead, save visualizations instead as a vector image via PDF or SVG: `plt.savefig(\"yourfilename.pdf\")`\n",
    "\n",
    "> *Why not PNG or JPEG?* Raster image formats such as PNG and JPEG store pictures as compressed information on the colors of pixels. They are great for cases like photographs, where we want to minimize the perceived loss of visual quality while saving storage space.\n",
    "> But with visualizations, we care about *semantic* components: selected fonts, precise curves, and exact distances. Vector images are recorded as coded paths with specific characteristics. A PDF or SVG saved from Matplotlib can be later opened in a program such as Inkscape or Adobe Illustrator to make useful changes. You can shrink the size of a label, change the font used in a title, adjust the position of legends, or scale the entire visualization to the size of a large poster, all with no loss in quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mpl.rc_file_defaults() # reset to defaults\n",
    "\n",
    "# Scale all font sizes slightly smaller\n",
    "sns.set_context('paper')\n",
    "\n",
    "grid = sns.catplot(\n",
    "    data=semester_df,\n",
    "    x='team_size', \n",
    "    y='modal_suborg', \n",
    "    kind='strip',\n",
    "    marker='.',\n",
    "    jitter=0.2,\n",
    "    palette=sns.color_palette('deep'),\n",
    "    order=semester_df['modal_suborg'].value_counts(ascending=True).index\n",
    ")\n",
    "\n",
    "sns.color_palette()\n",
    "grid.set_axis_labels(\"Size of Student's Team(s) during Semester\", \"Modal Suborganization of Federal Funding\")\n",
    "add_sourcing(plt, 'Sources: IRIS UMETRICS, NCSES SED')\n",
    "\n",
    "# Save the current state of the plot to PDF\n",
    "plt.savefig(\"example.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "<font color = red><h2> Checkpoint #3: Saving Visualizations</h2></font>\n",
    "\n",
    "Try saving some of the visualizations that we've created, either from previous checkpoints, or from the examples shown. Additionally, think about the underlying data. We'll cover this in more detail later, but to export anything you create from the ADRF, you'll need to show that the underlying data for any visualizations you want to export pass the disclosure review process. Carefully considering the data and the process that goes into any visualization you save is the first step towards making sure you are able to export the figures you create."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `plt.savefig()` function from above and specify the format that you are interested in. We will talk more about the disclosure review and export process in Module 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## More Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Matplotlib\n",
    "\n",
    "* [Matplotlib Documentation](https://matplotlib.org)\n",
    "\n",
    "* [Matplotlib visualization tutorials](https://matplotlib.org/tutorials/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Seaborn\n",
    "\n",
    "* [Seaborn Documentation](http://seaborn.pydata.org)\n",
    "\n",
    "* [Advanced Functionality in Seaborn](blog.insightdatalabs.com/advanced-functionality-in-seaborn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Colors\n",
    "\n",
    "Tools like [Adobe Color](https://color.adobe.com) and this [Hex Calculator](https://www.w3schoosl.com/colors/colors_hexadecimal.asp) can help you get used to the hex triplet system.\n",
    "\n",
    "The [official XKCD color list](https://xkcd.com/color/rgb/) lists all the named colors and their hex triplets; w3schools.com has also published an [XKCD color chart](https://www.w3schools.com/colors/colors_xkcd.asp) with larger swatches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Other Python Visualization Libraries\n",
    "\n",
    "[A Dramatic Tour through Python's Data Visualization Landscape](https://dsaber.com/2016/10/02/a-dramatic-tour-through-pythons-data-visualization-landscape-including-ggplot-and-altair) discusses and compares Matplotlib, seaborn, ggplot, and Altair.\n",
    "\n",
    "* [Plotly](https://plot.ly) focuses on interactive visualizations, including online hosting.\n",
    "\n",
    "* [Bokeh](http://bokeh.pydata.org) priotizes ease of use, also with an emphasis on in-browser, interactive charts.\n",
    "\n",
    "* [ggplot](http://ggplot.yhathq.com) is largely a port of R's heavily-used ggplot2 library, inspired by *The Grammar of Graphics*.\n",
    "\n",
    "* [Altair](https://altair-viz.github.io) is designed to be accessible and language independent, using the Vega-Lite syntax."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-ada",
   "language": "python",
   "name": "py3-ada"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
